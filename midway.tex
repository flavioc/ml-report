\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09


\title{Structured Statistical Code Prediction}

\author{
  Cyrus Omar\\
  \texttt{comar@cs.cmu.edu}
  \And
  Salil Joshi\\
  \texttt{salilj@cs.cmu.edu}
  \And Fl\'avio Cruz\\
  \texttt{fmfernan@cs.cmu.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\section*{Introduction}
Programming languages are formal systems with rich syntactic and semantic structure. They are
also human systems, in that they are used extensively by people in patterned ways to express their
intent. Many tools have been designed to help people write code more efficiently by predicting
the developer’s intent. For example, code completion systems in editors like Eclipse display pop-
up menus containing members relevant to the class that the developer is working with, potentially
saving the developer keystrokes. Typical code completion systems use only syntactic and semantic
information about the language itself, rather than data about how developers have written programs
in the past. Recent work by Hindle et al. [1] showed that source code could be modeled statistically
using a simple n-gram model that used a simple tokenized representation of source code.

Our project aims to unite these structured and statistical approaches to source code prediction.
Specifically, rather than using a linear, tokenized representation of source code, we would like to do
prediction on a more natural representation of source code – the syntax tree.  We also utilize the semantics of the language by conditioning our prediction on the expected \emph{type} of the expression, and on the \emph{context} in which the expression occurs (i.e.\ whether the expression is an argument to a function, or the test used in an if statement, etc.).

The expected type of the expression is used to constrain the prediction space.  For example, if a
user has entered the code \texttt{Planet destination = }, where Planet is an enumeration con-
taining Mercury, Venus, Earth, etc. (but not Pluto), then we know that the only valid predictions are members of the Planet enumeration, variables of type Planet in the scope and functions returning Planet. 

The context in this example is an assignment context . The prediction is then made based on how often an expression in such a context was found to be a literal or a variable or a function call in our prior analysis of code corpuses. Our claim is that code is written in repeatable patterns, and that the context in which a piece of code appears is relevant when identifying the pattern, and therefore relevant when making a prediction.


TODO Write applications somewhere\\
Improved code prediction is useful as an IDE tool to increase productivity by speeding up the more mundane aspects of programming.

Useful for programmers with physical impairments.

Useful for debugging? Maybe? Somehow?

\section*{Related Work}
\section*{Method}
We use the Java programming language to perform experiments using our methodology. The ideas underlying our project are applicable to any statically typed programming language, but Java has some advantages that are are relevant to us. First, there are large Java code corpuses freely available. Second, there is prior work on predicting Java programs that we can use as a basis for evaluating our model \cite{something}. Lastly, we can use the Eclipse IDE which gives us access to a powerful toolchain for working with Java programs.

\subsection*{Model}
The model we use for code prediction can be stated as:
$$ e = \arg\max_e P(e ~|~ \texttt{type} , \texttt{context} ) $$

Here \texttt{type} is the expected type of the expression. If a given expression $e$ does not have the required type, then $P(e ~|~ \texttt{type})$ is necessarily $0$ (since $e$ cannot appear in this position in any well-typed programming). This drastically reduces our search space.

\texttt{context} is the program context in which this expression is to appear. Some examples of contexts:
\begin{itemize}
  \item Assignment: \texttt{Planet p =} $\Box$
  \item If-test: $\texttt{if }\Box\texttt{ then}\ldots\texttt{else}\ldots$
  \item Function arguments: $\texttt{O.foo }\Box$
\end{itemize}

The $e$ in the equation above ranges over possible expressions. However we do not search over \emph{all} possible expressions. This is impossible since there may be an infinite number of well formed expressions. Moreover, it is unneccessary since we need only predict the \emph{root} of the syntax tree for $e$. The rest of the nodes in the tree can then be predicted recursively.

Thus we first identify the three forms that the tree $e$ can take:
\begin{itemize}
  \item $e$ may be just a literal of the appropriate type. For example if the type is an \texttt{enum}, $e$ may be a member of that \texttt{enum}
  \item $e$ may be a variable in scope of the appropriate type.
  \item $e$ may be a call to a function that returns the appropriate type. In this case, we predict only the function itself. The arguments to the function can be predicted later recursively.
\end{itemize}

\subsection*{Analysis}
The parameters to our model then, are the probabilities of occurrences of each of these three forms (given the type and context), and in particular the probabilities of occurences of particular expressions of each form. Thus while analysizing a code corpus, we calculate the following:
\begin{itemize}
  \item Probability that $e$ is a literal: $P(e \text{ is a literal} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a specific literal $l$, given that it is \emph{some} literal: \\$P(e = l ~|~ e \text{ is a literal},  \texttt{type} , \texttt{context} )$
    \end{itemize}
  \item Probability that $e$ is some (any) variable $x$ in scope: $P(e = x ~|~ \texttt{type} , \texttt{context})$
  \item Probability that $e$ is a function call: $P(e \text{ is a function call} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a call to a specific function $f$, given that it is \emph{some} function call: \\$P(e = f \ldots ~|~ e \text{ is a function call},  \texttt{type} , \texttt{context} )$
    \end{itemize}
\end{itemize}

\subsection*{Prediction}

Since the number of possible contexts is small and finite, we will always have statistical data about expressions in any given context. However, this is not the case for types, since a programmer may define types that we have never seen before. If this situation occurs, we need to condition probabilities of expressions on just the context and not the type. 
$$ e = \arg\max_e P(e ~|~ \texttt{context} ) = \arg\max_e \Sigma_{\texttt{type}} P(e ~|~ \texttt{type} , \texttt{context} ) $$

Then the \emph{form} of $e$ can be predicted using this equation, however it will not give us a useful prediction for the specific expression (since, if we have not seen the expected type before, we cannot have seen expressions of that type before). So when making a prediction, we use a two-step method: First predict the most likely form of the predicted expression, then either predict or try to guess the specific expression. There are three possibilities for the form of $e$:
\begin{itemize}
  \item Literal: If we have data available about probabilities of literals of the expected type, then we may use that to make a prediction. However if we do not, then we predict \emph{any} literal of the expected type.
  \item Variable: Here there are two possibilities. We may either predict the most \emph{recently} used variable in scope, or the most \emph{frequently} used variable in scope. We need further analysis and experimentation to decide which of these two possibilities gives more useful results.
  \item Function Call: Similar to the case for literals. If we have data available about probabilities of functions that return the expected type, then we may use that to make a prediction. However if we do not, then we predict any function that returns the expected type.
\end{itemize}

This two-step approach negates the need to solve the difficult problem of smoothing our data. Smoothing at the level of contexts is unneccessary since we always have enough data. Smoothing at the level of types is also not required, since the prediction algorithm can handle cases where we have insufficient data in a natural fashion.

\subsection*{Implementation}

We have written code for analyzing code corpuses as a plugin to the popular Eclipse IDE. This allows us to use Eclipse's Java parser and typechecker. Eclipse also provides functions that make it easy to walk through the source code to collect the data we need.

To collect statistics about a given code corpus, we first parse each Java file and generate the Abstract Syntax Tree (AST) with the corresponding type information. For this task, we use the JDT (Java Development Tools) library. Then, we run three visitors that identify the three forms that each expression can take:

\begin{description}
   \item[Literal Visitor:] For primitive types such as integers, floats, doubles or strings, we count the frequency of each literal in the code. For enumeration types (like \texttt{Planet}), we count the frequency of each element of the enumeration.

   \item[Variable Visitor:] For each type, we count the number of times a variable of this type was referenced in the code.

   \item[Method Visitor:] We group methods by the return type, so that we can count the number of times each method is used.

\end{description}

\section*{Experiments}

Although the best method to test the quality of our models would be to perform an user study, we are a bit more limited in time and resources. Therefore, we will use already available software code to to automatically test our prediction facilities.

Our experiments will make use of freely available code corpuses code such as Qualitas Corpus (\url{http://qualitascorpus.com/}).

From each code corpus, we leave out one source code file to be used as a test.
We create many partial versions that end with the start of a function call or variable declaration. This emulates what would happen when a programmer would try to write the code inside the IDE. Therefore, we can apply our model to predict which code is mostly likely to be typed next. Finally, we compute the average of the classification error for this single file from all the partial versions.

To get a better estimation of the classification error, we will build $K$ different models of the same code corpus by leaving one file out and then building the model using the remaining files. The file left out is then used as a test as described previously. Finally, we compute the average of the error from the classification error of the $K$ models.

\section*{Conclusion}

\end{document}
