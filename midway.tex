\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{amsmath}
\usepackage{amssymb}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09


\title{Structured Statistical Code Prediction}

\author{
  Cyrus Omar\\
  \texttt{comar@cs.cmu.edu}
  \And
  Salil Joshi\\
  \texttt{salilj@cs.cmu.edu}
  \And Fl\'avio Cruz\\
  \texttt{fmfernan@cs.cmu.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\section*{Introduction}
Programming languages are formal systems with rich syntactic and semantic structure. They are also human systems, in that they are used extensively by people in patterned ways to express their intent. Many tools have been designed to help people write code more efficiently by predicting the developer's intent. For example, code completion systems in editors like Eclipse display pop-up menus containing members relevant to the class that the developer is working with, potentially saving the developer keystrokes. Typical code completion systems use only syntactic and semantic information about the language itself. Recent work by Hindle et al. [1] demonstrated that source code could be modeled statistically using a simple $n$-gram model that used a lexically-tokenized representation of code and suggested completions based on this information instead.

Our project aims to unite the {\em structured} and {\em statistical} approaches to source code prediction. More specifically, rather than using a linear, tokenized representation of source code, we would like to do prediction on a more natural representation of source code -- the {\em syntax tree}. Moreover, we would like to constrain our predictions using on the semantics of the language and libraries being used, in particular by using {\em type information} to constrain the prediction space drastically. For example, if a user has entered the Java code \verb|Planet destination = |, where \verb|Planet| is an enumeration containing \verb|Mercury|, \verb|Venus|, \verb|Earth|, etc. (but not \verb|Pluto|), then we can {\em structurally} constrain the completion by restricting it to members of the \verb|Planet| enumeration, variables of type \verb|Planet| in the scope and functions returning \verb|Planet|, then {\em statistically} predict the value based on an analysis of prior code corpuses that contain expressions of type \verb|Planet|, perhaps in a similar context.

In addition to its applications to code completion systems in code editors like Eclipse, more accurate source code prediction could be useful for other tools. For example, programmers with severe physical impairments may benefit from more specialized tools that allow them convey source code using interface devices more limited than a keyboard, incorporating predictions to reduce the amount of information that needs to be conveyed.
\section*{Related Work}


\section*{Method}
We use the Java programming language to perform experiments using our methodology. The ideas underlying our project are applicable to any statically typed programming language, but Java has some advantages that are are relevant to us. First, there are large Java code corpuses freely available. Second, there is prior work on predicting Java programs that we can use as a basis for evaluating our model \cite{something}. Lastly, we can use the Eclipse IDE which gives us access to a powerful toolchain for working with Java programs.

\subsection*{Model}
The model we use for code prediction can be stated as:
$$ e = \arg\max_e P(e ~|~ \texttt{type} , \texttt{context} ) $$

Here \texttt{type} is the expected type of the expression. If a given expression $e$ does not have the required type, then $P(e ~|~ \texttt{type})$ is necessarily $0$ (since $e$ cannot appear in this position in any well-typed programming). This drastically reduces our search space.

\texttt{context} is the program context in which this expression is to appear. Some examples of contexts:
\begin{itemize}
  \item Assignment: \texttt{Planet p =} $\Box$
  \item If-test: $\texttt{if }\Box\texttt{ then}\ldots\texttt{else}\ldots$
  \item Function arguments: $\texttt{O.foo }\Box$
\end{itemize}

The $e$ in the equation above ranges over possible expressions. However we do not search over \emph{all} possible expressions. This is impossible since there may be an infinite number of well formed expressions. Moreover, it is unneccessary since we need only predict the \emph{root} of the syntax tree for $e$. The rest of the nodes in the tree can then be predicted recursively.

Thus we first identify the three forms that the tree $e$ can take:
\begin{itemize}
  \item $e$ may be just a literal of the appropriate type. For example if the type is an \texttt{enum}, $e$ may be a member of that \texttt{enum}
  \item $e$ may be a variable in scope of the appropriate type.
  \item $e$ may be a call to a function that returns the appropriate type. In this case, we predict only the function itself. The arguments to the function can be predicted later recursively.
\end{itemize}

\subsection*{Analysis}
The parameters to our model then, are the probabilities of occurrences of each of these three forms (given the type and context), and in particular the probabilities of occurences of particular expressions of each form. Thus while analysizing a code corpus, we calculate the following:
\begin{itemize}
  \item Probability that $e$ is a literal: $P(e \text{ is a literal} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a specific literal $l$, given that it is \emph{some} literal: \\$P(e = l ~|~ e \text{ is a literal},  \texttt{type} , \texttt{context} )$
    \end{itemize}
  \item Probability that $e$ is some (any) variable $x$ in scope: $P(e = x ~|~ \texttt{type} , \texttt{context})$
  \item Probability that $e$ is a function call: $P(e \text{ is a function call} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a call to a specific function $f$, given that it is \emph{some} function call: \\$P(e = f \ldots ~|~ e \text{ is a function call},  \texttt{type} , \texttt{context} )$
    \end{itemize}
\end{itemize}

\subsection*{Prediction}

Since the number of possible contexts is small and finite, we will always have statistical data about expressions in any given context. However, this is not the case for types, since a programmer may define types that we have never seen before. If this situation occurs, we need to condition probabilities of expressions on just the context and not the type. 
$$ e = \arg\max_e P(e ~|~ \texttt{context} ) = \arg\max_e \Sigma_{\texttt{type}} P(e ~|~ \texttt{type} , \texttt{context} ) $$

Then the \emph{form} of $e$ can be predicted using this equation, however it will not give us a useful prediction for the specific expression (since, if we have not seen the expected type before, we cannot have seen expressions of that type before). So when making a prediction, we use a two-step method: First predict the most likely form of the predicted expression, then either predict or try to guess the specific expression. There are three possibilities for the form of $e$:
\begin{itemize}
  \item Literal: If we have data available about probabilities of literals of the expected type, then we may use that to make a prediction. However if we do not, then we predict \emph{any} literal of the expected type.
  \item Variable: Here there are two possibilities. We may either predict the most \emph{recently} used variable in scope, or the most \emph{frequently} used variable in scope. We need further analysis and experimentation to decide which of these two possibilities gives more useful results.
  \item Function Call: Similar to the case for literals. If we have data available about probabilities of functions that return the expected type, then we may use that to make a prediction. However if we do not, then we predict any function that returns the expected type.
\end{itemize}

This two-step approach negates the need to solve the difficult problem of smoothing our data. Smoothing at the level of contexts is unneccessary since we always have enough data. Smoothing at the level of types is also not required, since the prediction algorithm can handle cases where we have insufficient data in a natural fashion.

\subsection*{Implementation}

We have written code for analyzing code corpuses as a plugin to the popular Eclipse IDE. This allows us to use Eclipse's Java parser and typechecker. Eclipse also provides functions that make it easy to walk through the source code to collect the data we need.

To collect statistics about a given code corpus, we first parse each Java file and generate the Abstract Syntax Tree (AST) with the corresponding type information. For this task, we use the JDT (Java Development Tools) library. Then, we run three visitors that identify the three forms that each expression can take:

\begin{description}
   \item[Literal Visitor:] For primitive types such as integers, floats, doubles or strings, we count the frequency of each literal in the code. For enumeration types (like \texttt{Planet}), we count the frequency of each element of the enumeration.

   \item[Variable Visitor:] For each type, we count the number of times a variable of this type was referenced in the code.

   \item[Method Visitor:] We group methods by the return type, so that we can count the number of times each method is used.

\end{description}

\section*{Experiment}

Our experiments will make use of 

\section*{Conclusion}

\section*{References}
\small{
[1] A.ÊHindle, E.ÊT. Barr, Z.ÊSu, M.ÊGabel, and P.ÊDevanbu. On the naturalness of software. In Proceedings of the 2012 International Conference on Software Engineering, ICSE 2012, pages 837Ð847, Piscataway, NJ, USA, 2012. IEEE Press.

[2] M. Bruch, M. Monperrus, and M. Mezini, ÒLearning from examples to improve code completion systems,Ó in Proceedings, ACM SIGSOFT ESEC/FSE, 2009.

[3] D. Hou and D. Pletcher, ÒAn Evaluation of the Strategies of Sorting, Filtering, and Grouping API Methods for Code Com- pletion,Ó in Proceedings, ICSM, 2011.
}
\end{document}
