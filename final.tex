\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09

\title{Structured Statistical Code Prediction}

\author{
  Cyrus Omar\\
  \texttt{comar@cs.cmu.edu}
  \And
  Salil Joshi\\
  \texttt{salilj@cs.cmu.edu}
  \And Fl\'avio Cruz\\
  \texttt{fmfernan@cs.cmu.edu}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\section*{Introduction}
Programming languages are formal systems with rich syntactic and semantic structure. They are
also human systems, in that they are used extensively by people in patterned ways to express their
intent. Many tools are designed to help people write code more efficiently by predicting
the developer's intent. For example, code completion systems in editors like Eclipse display pop-up menus containing members relevant to the class that the developer is working with. 

Typical code completion systems use only syntactic and semantic
information about the language and APIs, rather than data about how developers have written programs
in the past. Recent work by Hindle et al.~\cite{Hindle:2012:NS:2337223.2337322} showed, however, that source code could be modeled statistically
using a simple n-gram model that used a tokenized, sequential representation of source code. 

Our project aims to unite the structured and statistical approaches to source code prediction.
Specifically, rather than using a tokenized representation of source code, we would like to do
statistical prediction on a more natural representation of source code: the syntax tree.  We constrain our predictions by utilizing structural information, specifically: the expected \emph{type} of the expression, and the syntactic \emph{context} in which the expression occurs (e.g. whether the expression is an argument of a function call, the guard of an \verb|if| statement, etc.).

For example, if a user has entered the code \texttt{Planet destination = }, where \verb|Planet| is an enumeration containing \verb|Mercury|, \verb|Venus|, \verb|Earth|, etc. (but not \verb|Pluto|), then we know that the only valid predictions are literal members of the \verb|Planet| enumeration, variables of type \verb|Planet| in the scope or calls to methods with return type \texttt{Planet}. The context in this example is an assignment context. The prediction is then made based first on how often an expression of type \verb|Planet| in such context was found to be a literal or a variable or a method invocation from our prior analysis of a code corpus, and further refined based on information about specific literals, variables or methods that is available from these corpus analyses as well (smoothed using some suitable method in cases where enough information is not available).

In addition to applications to code completion systems in code editors like Eclipse, more accurate source code prediction techniques could be useful for other tools. For example, programmers with severe physical impairments may benefit from more specialized tools that allow them convey source code using devices more limited than a keyboard, incorporating predictions to reduce the amount of information that needs to be conveyed explicitly.

\section*{Related Work}
As mentioned above, work by Hindle et al. \cite{Hindle:2012:NS:2337223.2337322} showed that using a simple $n$-gram model of source code, represented as sequences of tokens, produced reasonably accurate predictions. This work (published this summer) suggested constraining this model using structural information as future work that might further improve predictions. 

Work examining the ``uniqueness'' of software has found that source code can often be decomposed into commonly-seen motifs \cite{Gabel:2010:FSE}, further suggesting that prediction that uses structural information may be a particularly helpful approach in the domain of source code.

Several code completion systems that incorporate statistical information in a limited context, such as specifically for predicting which methods of a class will be called, have been produced in the past \cite{Bruch:2009:LEI:1595696.1595728,robbes_how_2008}. The work by Robbes and Lanza \cite{robbes_how_2008} defined a methodology by which to compare different prediction engines in such settings, which can be generalized to our approach as well. 

Other systems, such as Calcite \cite{mooty_calcite:_2010}, have produced contextually-relevant {\em code snippets} or examples drawn from a code corpus or web search, where more frequently encountered snippets are preferentially shown. These can be considered special cases of the approach we are taking in our project.


\section*{Method}
We use the Java programming language to perform experiments using our methodology. The ideas underlying our project are applicable to any statically typed programming language, but Java has some advantages that are are relevant to us. First, there are large Java code corpuses freely available. Second, there is prior work on predicting Java programs that we can use as a basis for evaluating our model (see above). Lastly, we can use the Eclipse IDE which gives us access to a powerful toolchain for working with Java programs.

\subsection*{Model}
The model we use for code prediction can be stated as:
$$ e = \arg\max_e P(e ~|~ \texttt{type} , \texttt{context} ) $$

Here \texttt{type} is the expected type of the expression. If a given expression $e$ does not have the required type, then $P(e ~|~ \texttt{type})$ is necessarily $0$ (since $e$ cannot appear in this position in any well-typed programming). This drastically reduces our search space.

\texttt{context} is the program context in which this expression is to appear. Some examples of contexts:
\begin{itemize}
  \item Assignment: \texttt{Planet p =} $\Box$
  \item If-test: $\texttt{if }\Box\texttt{ then}\ldots\texttt{else}\ldots$
  \item Method arguments: $\texttt{O.foo }\Box$
\end{itemize}

The $e$ in the equation above ranges over possible expressions. However we do not search over \emph{all} possible expressions. This is impossible since there may be an infinite number of well formed expressions. Moreover, it is unneccessary since we need only predict the \emph{root} of the syntax tree for $e$. The rest of the nodes in the tree can then be predicted recursively.

Thus we first identify the three forms that the tree $e$ can take:
\begin{itemize}
  \item $e$ may be just a literal of the appropriate type. For example if the type is an \texttt{enum}, $e$ may be a member of that \texttt{enum}
  \item $e$ may be a variable in scope of the appropriate type.
  \item $e$ may be a call to a method that returns the appropriate type. In this case, we predict only the method itself. The arguments to the method can be predicted later recursively.
\end{itemize}

\subsection*{Analysis}
The parameters to our model then, are the probabilities of occurrences of each of these three forms (given the type and context), and in particular the probabilities of occurences of particular expressions of each form. Thus while analysizing a code corpus, we calculate the following:
\begin{itemize}
  \item Probability that $e$ is a literal: $P(e \text{ is a literal} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a specific literal $l$, given that it is \emph{some} literal: \\$P(e = l ~|~ e \text{ is a literal},  \texttt{type} , \texttt{context} )$
    \end{itemize}
  \item Probability that $e$ is some (any) variable $x$ in scope: $P(e = x ~|~ \texttt{type} , \texttt{context})$
  \item Probability that $e$ is a method call: $P(e \text{ is a method call} ~|~  \texttt{type} , \texttt{context} ) $
    \begin{itemize}
      \item Probability that $e$ is a call to a specific method $f$, given that it is \emph{some} method call: \\$P(e = f \ldots ~|~ e \text{ is a method call},  \texttt{type} , \texttt{context} )$
    \end{itemize}
\end{itemize}

\subsection*{Prediction}

Since the number of possible contexts is small and finite, we will always have statistical data about expressions in any given context. However, this is not the case for types, since a programmer may define types that we have never seen before. If this situation occurs, we need to condition probabilities of expressions on just the context and not the type. 
$$ e = \arg\max_e P(e ~|~ \texttt{context} ) = \arg\max_e \Sigma_{\texttt{type}} P(e ~|~ \texttt{type} , \texttt{context} ) $$

Then the \emph{form} of $e$ can be predicted using this equation, however it will not give us a useful prediction for the specific expression (since, if we have not seen the expected type before, we cannot have seen expressions of that type before). So when making a prediction, we use a two-step method: First predict the most likely form of the predicted expression, then either predict or try to guess the specific expression. There are three possibilities for the form of $e$:
\begin{description}
  \item[Literal:] If we have data available about probabilities of literals of the expected type, then we may use that to make a prediction. However if we do not, then we predict \emph{any} literal of the expected type.
  \item[Variable:] Here there are two possibilities. We may either predict the most \emph{recently} used variable in scope, or the most \emph{frequently} used variable in scope. We need further analysis and experimentation to decide which of these two possibilities gives more useful results.
  \item[Method Call:] Similar to the case for literals. If we have data available about probabilities of methods that return the expected type, then we may use that to make a prediction. However if we do not, then we predict any method that returns the expected type.
\end{description}

This two-step approach negates the need to solve the difficult problem of smoothing our data. Smoothing at the level of contexts is unneccessary since we always have enough data. Smoothing at the level of types is also not required, since the prediction algorithm can handle cases where we have insufficient data in a natural fashion.

\subsection*{Implementation}

We implemented our prediction model using the Eclupse Java Development Tools (JDT) library

We have written code for analyzing code corpuses as a plugin to the popular Eclipse IDE. This allows us to use Eclipse's Java parser and typechecker. Eclipse also provides functions that make it easy to walk through the source code to collect the data we need.

To collect statistics about a given code corpus, we first parse each Java file and generate the Abstract Syntax Tree (AST) with the corresponding type information. For this task, we use the JDT (Java Development Tools) library. Then, we run three visitors that identify the three forms that each expression can take:

\begin{description}
   \item[Literal Visitor:] For primitive types such as integers, floats, doubles or strings, we count the frequency of each literal in the code. For enumeration types (like \texttt{Planet}), we count the frequency of each element of the enumeration.

   \item[Variable Visitor:] For each type, we count the number of times a variable of this type was referenced in the code.

   \item[Method Visitor:] We group methods by the return type, so that we can count the number of times each method is used.
\end{description}

\section*{Experiments}

Although the best method to test the quality of our models would be to perform an user study, we are a bit more limited in time and resources. Therefore, we used already available software code to automatically test our prediction facilities.

Our experiments makes use of freely available code corpuses listed in Qualitas Corpus (\url{http://qualitascorpus.com/}).
Table~\ref{tab:projects} presents the projects we picked from the catalogue. We also show the number of files and the
lines of code (LOC) for each project.

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Project} & \textbf{\# Files} & \textbf{\# LOC} & \textbf{Description} \\
\hline
Ant & 1196 & 256039 & a software tool for automating software build processes \\
ANTLR & 394 & 66845 & a language tool that provides a framework for implementing compilers \\
Art Of Illusion & 487 & 153645 & an open source 3D modelling and rendering studio \\
Axion & 237 & 42329 & a relational database system supporting SQL and JDBC \\
Batik & 1664 & 366506 & a library for manipulation of SVG files \\
FindBugs & 1149 & 207827 & a program that uses static analysis to look for bugs in Java code \\
JFreeChart & 1005 & 321551 & a library for displaying professional charts \\
\hline
\end{tabular}
\caption{Software projects used in our experiments.}
\label{tab:projects}
\end{table}

For each project, we consider a subset of files for testing, the test set, and all the remaining files as the training set.
In our experiments we want to determine the probability of our model to predict the expressions found in the test set (the prediction rate), given the parameters we found by analyzing the training set.

To get a more accurate prediction rate, we use a ten-fold cross validation, where we select 10\% of the files at random as the test set and build our model by using the remaining 90\% of the files. For each file in the test set, we visit all the expressions (including sub-expressions) and compute the prediction rate. We then average the prediction rate of all expressions found to produce the prediction rate for that file. Finally, we average the prediction rate of all files to get a prediction rate for the current iteration of the cross validation procedure.

\section*{Conclusion}

\bibliography{midway}
\bibliographystyle{plain}

\end{document}
